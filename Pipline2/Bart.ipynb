{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aw1Krv1FYWkI"
      },
      "source": [
        "# Nouvelle section"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y transformers accelerate\n",
        "\n",
        "# Supprimer à la main les restes éventuels\n",
        "!rm -rf /usr/local/lib/python3.12/dist-packages/transformers\n",
        "!rm -rf /usr/local/lib/python3.12/dist-packages/transformers-*.dist-info\n",
        "\n",
        "# Réinstallation propre\n",
        "!pip install \"transformers==4.46.2\" \"accelerate>=1.1.0\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "e6QUG3hChQcr",
        "outputId": "50995dd2-a4e9-4664-dcec-f024f79d3313"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: transformers 4.57.3\n",
            "Uninstalling transformers-4.57.3:\n",
            "  Successfully uninstalled transformers-4.57.3\n",
            "Found existing installation: accelerate 1.12.0\n",
            "Uninstalling accelerate-1.12.0:\n",
            "  Successfully uninstalled accelerate-1.12.0\n",
            "Collecting transformers==4.46.2\n",
            "  Downloading transformers-4.46.2-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate>=1.1.0\n",
            "  Downloading accelerate-1.12.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers==4.46.2) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.12/dist-packages (from transformers==4.46.2) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.46.2) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.46.2) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.46.2) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.46.2) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers==4.46.2) (2.32.4)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.46.2) (0.7.0)\n",
            "Collecting tokenizers<0.21,>=0.20 (from transformers==4.46.2)\n",
            "  Downloading tokenizers-0.20.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers==4.46.2) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate>=1.1.0) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate>=1.1.0) (2.9.0+cu126)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.46.2) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.46.2) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.46.2) (1.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.1.0) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.1.0) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.1.0) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.1.0) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.1.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.1.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.1.0) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.1.0) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.1.0) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.1.0) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.1.0) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.1.0) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.1.0) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.1.0) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.1.0) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.1.0) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.1.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.1.0) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.1.0) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.1.0) (3.5.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.46.2) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.46.2) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.46.2) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.46.2) (2025.11.12)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate>=1.1.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate>=1.1.0) (3.0.3)\n",
            "Downloading transformers-4.46.2-py3-none-any.whl (10.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m85.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading accelerate-1.12.0-py3-none-any.whl (380 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.9/380.9 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.20.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m94.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tokenizers, transformers, accelerate\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.22.1\n",
            "    Uninstalling tokenizers-0.22.1:\n",
            "      Successfully uninstalled tokenizers-0.22.1\n",
            "Successfully installed accelerate-1.12.0 tokenizers-0.20.3 transformers-4.46.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "accelerate",
                  "tokenizers",
                  "transformers"
                ]
              },
              "id": "41c234a6e79a4c309a905117a6b941ec"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y transformers optimum-quanto accelerate\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSqTuW2bWLQH",
        "outputId": "c563a647-b13c-43d3-bb3c-896deb2236f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: transformers 4.46.2\n",
            "Uninstalling transformers-4.46.2:\n",
            "  Successfully uninstalled transformers-4.46.2\n",
            "\u001b[33mWARNING: Skipping optimum-quanto as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mFound existing installation: accelerate 1.12.0\n",
            "Uninstalling accelerate-1.12.0:\n",
            "  Successfully uninstalled accelerate-1.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"transformers==4.44.2\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 686
        },
        "id": "HOg2mp0-WMLx",
        "outputId": "0c3ea21e-0203-4bb3-b0f9-3a071418c396"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==4.44.2\n",
            "  Downloading transformers-4.44.2-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (2.32.4)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (0.7.0)\n",
            "Collecting tokenizers<0.20,>=0.19 (from transformers==4.44.2)\n",
            "  Downloading tokenizers-0.19.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.44.2) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.44.2) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.44.2) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.44.2) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.44.2) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.44.2) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.44.2) (2025.11.12)\n",
            "Downloading transformers-4.44.2-py3-none-any.whl (9.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m105.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.19.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m115.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.20.3\n",
            "    Uninstalling tokenizers-0.20.3:\n",
            "      Successfully uninstalled tokenizers-0.20.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "peft 0.18.0 requires accelerate>=0.21.0, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tokenizers-0.19.1 transformers-4.44.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tokenizers",
                  "transformers"
                ]
              },
              "id": "ff80ebc999f6409a9de1a4135cc5f507"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BartTokenizer, BartForConditionalGeneration\n",
        "\n",
        "print(torch.__version__)\n",
        "\n",
        "tokenizer_bart = BartTokenizer.from_pretrained(\"facebook/bart-base\")\n",
        "model_bart = BartForConditionalGeneration.from_pretrained(\"facebook/bart-base\")\n",
        "\n",
        "print(\"BART chargé ✅\")\n"
      ],
      "metadata": {
        "id": "r2UidihBWPRb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "import inspect\n",
        "\n",
        "print(\"Version :\", transformers.__version__)\n",
        "print(\"Fichier :\", transformers.__file__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121,
          "referenced_widgets": [
            "96a629cf6f7340ae91c8c6f0adae94e1",
            "8ca94892cb9f4c63b27db250f428d8e0",
            "1fb00f03c2ba4829af4f41254d15e1aa",
            "c5741689b5074a97a09868237ce40af3",
            "af464c4e2c5e4a43a1443588f713ef7f",
            "22a35d8ec9e24cd1a263e388ce26db18",
            "e55fc1fe85334cf1b179f0e3467b8b7b",
            "5067ea71ac3a4ceface7747a3c66ff4f",
            "6a73c9cd1c174834962bbeecf85fb568",
            "170229f5b24d45b0be410500f4b17a41",
            "c4fe33e4955a4c60b818b571def0cc8a"
          ]
        },
        "id": "PLp6NLxkh53Q",
        "outputId": "0f87c6aa-2052-4999-82a5-7560e8ff4959"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "96a629cf6f7340ae91c8c6f0adae94e1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Version : 4.44.2\n",
            "Fichier : /usr/local/lib/python3.12/dist-packages/transformers/__init__.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BartTokenizer, BartForConditionalGeneration\n"
      ],
      "metadata": {
        "id": "TXsB6xBghtcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLxac-2Pe-3s",
        "outputId": "70d1f3e8-10d6-46a9-d566-8e08f821d0d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 8659\n",
            "Dev size  : 1034\n"
          ]
        }
      ],
      "source": [
        "# 1) Charger les paires préparées\n",
        "with open(\"/content/bart_train_pairsfinal.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    train_pairs = json.load(f)\n",
        "\n",
        "with open(\"/content/bart_dev_pairsfinal.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    dev_pairs = json.load(f)\n",
        "\n",
        "print(\"Train size:\", len(train_pairs))\n",
        "print(\"Dev size  :\", len(dev_pairs))\n",
        "\n",
        "\n",
        "# 2) Dataset pour BART\n",
        "class Text2SQLDataset(Dataset):\n",
        "    def __init__(self, pairs, tokenizer, max_input_len=512, max_output_len=256):\n",
        "        self.pairs = pairs\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_input_len = max_input_len\n",
        "        self.max_output_len = max_output_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.pairs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.pairs[idx]\n",
        "\n",
        "        enc = self.tokenizer(\n",
        "            item[\"input\"],\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=self.max_input_len,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "\n",
        "        dec = self.tokenizer(\n",
        "            item[\"output\"],\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=self.max_output_len,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": enc[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": enc[\"attention_mask\"].squeeze(0),\n",
        "            \"labels\": dec[\"input_ids\"].squeeze(0),\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225,
          "referenced_widgets": [
            "61c50453f1754a95a4ea429f2a6efba1",
            "db5b8cc435ff43e69f072228c8cd926e",
            "ab79fa562b494d9c9ea4962ab4586e48",
            "3322f42c126f4985b4fe5b6aec831b1e",
            "990bb816181e47998ee36f170b04bfae",
            "1ca8cd492666424c894f4dff8775884c",
            "be34db09033246b48fc2991cb31a9402",
            "b9f677fdc3e0496bbfac13b14a50839e",
            "b620ac99fda34c5e9711d661be4294d4",
            "f9afe720fc5746898183c70240db1b76",
            "dc99795cde514c7a960d4f5be443ae73"
          ]
        },
        "id": "4nJmRnMJf0C3",
        "outputId": "db78f13d-9e35-4583-dc1f-a412876ac0f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/558M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "61c50453f1754a95a4ea429f2a6efba1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device utilisé : cuda\n"
          ]
        }
      ],
      "source": [
        "model_name = \"facebook/bart-base\"\n",
        "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
        "model = BartForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "train_dataset = Text2SQLDataset(train_pairs, tokenizer)\n",
        "val_dataset   = Text2SQLDataset(dev_pairs, tokenizer)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
        "val_loader   = DataLoader(val_dataset, batch_size=2, shuffle=False)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "print(\"Device utilisé :\", device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2URz03hUf3Cw"
      },
      "outputs": [],
      "source": [
        "def compute_exact_match(pred_texts, label_texts):\n",
        "    pred_texts = [p.strip().lower() for p in pred_texts]\n",
        "    label_texts = [l.strip().lower() for l in label_texts]\n",
        "    matches = [int(p == l) for p, l in zip(pred_texts, label_texts)]\n",
        "    return sum(matches) / len(matches) if matches else 0.0\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 3\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "pad_token_id = tokenizer.pad_token_id\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    print(f\"\\n===== ÉPOCH {epoch}/{num_epochs} =====\")\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for step, batch in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        input_ids      = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        labels         = batch[\"labels\"].to(device)\n",
        "\n",
        "        # Ignorer le padding dans la loss\n",
        "        labels_for_loss = labels.clone()\n",
        "        labels_for_loss[labels_for_loss == pad_token_id] = -100\n",
        "\n",
        "        outputs = model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            labels=labels_for_loss,\n",
        "        )\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        if (step + 1) % 100 == 0:\n",
        "            print(f\"  Step {step+1}/{len(train_loader)} - Loss: {loss.item():.4f}\")\n",
        "\n",
        "    avg_train_loss = total_loss / len(train_loader)\n",
        "    print(f\"Loss moyen entraînement : {avg_train_loss:.4f}\")\n",
        "\n",
        "    # ========= ÉVALUATION =========\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels_text = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            input_ids      = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            labels         = batch[\"labels\"].to(device)\n",
        "\n",
        "            # Génération de la prédiction\n",
        "            generated_ids = model.generate(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                max_length=256,\n",
        "            )\n",
        "\n",
        "            pred_texts = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
        "\n",
        "            # Texte de référence (labels)\n",
        "            labels_for_decode = labels.clone()\n",
        "            labels_for_decode[labels_for_decode == -100] = pad_token_id\n",
        "            label_texts = tokenizer.batch_decode(labels_for_decode, skip_special_tokens=True)\n",
        "\n",
        "            all_preds.extend(pred_texts)\n",
        "            all_labels_text.extend(label_texts)\n",
        "\n",
        "    exact_match = compute_exact_match(all_preds, all_labels_text)\n",
        "    print(f\"Exact Match dev : {exact_match:.4f}\")\n",
        "\n",
        "end_time = time.time()\n",
        "training_duration = end_time - start_time\n",
        "print(\"\\n==============================\")\n",
        "print(\"  ENTRAÎNEMENT TERMINÉ\")\n",
        "print(\"==============================\")\n",
        "print(f\"Temps total d'entraînement : {training_duration/60:.2f} minutes\")\n",
        "print(f\"                         = {training_duration:.2f} secondes\")\n",
        "print(\"==============================\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXHtLTSyizFl",
        "outputId": "27d5f868-a29a-4004-e5de-f8f1f9e29bc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== ÉPOCH 1/3 =====\n",
            "  Step 100/4330 - Loss: 1.5052\n",
            "  Step 200/4330 - Loss: 1.3007\n",
            "  Step 300/4330 - Loss: 1.0246\n",
            "  Step 400/4330 - Loss: 1.1014\n",
            "  Step 500/4330 - Loss: 1.0246\n",
            "  Step 600/4330 - Loss: 0.7283\n",
            "  Step 700/4330 - Loss: 1.4108\n",
            "  Step 800/4330 - Loss: 0.4135\n",
            "  Step 900/4330 - Loss: 0.6556\n",
            "  Step 1000/4330 - Loss: 0.8368\n",
            "  Step 1100/4330 - Loss: 0.5202\n",
            "  Step 1200/4330 - Loss: 0.6788\n",
            "  Step 1300/4330 - Loss: 0.2558\n",
            "  Step 1400/4330 - Loss: 0.3742\n",
            "  Step 1500/4330 - Loss: 0.7884\n",
            "  Step 1600/4330 - Loss: 0.6451\n",
            "  Step 1700/4330 - Loss: 0.3871\n",
            "  Step 1800/4330 - Loss: 0.6645\n",
            "  Step 1900/4330 - Loss: 0.4998\n",
            "  Step 2000/4330 - Loss: 0.2160\n",
            "  Step 2100/4330 - Loss: 1.0347\n",
            "  Step 2200/4330 - Loss: 0.3643\n",
            "  Step 2300/4330 - Loss: 0.8028\n",
            "  Step 2400/4330 - Loss: 1.2120\n",
            "  Step 2500/4330 - Loss: 0.3995\n",
            "  Step 2600/4330 - Loss: 0.4113\n",
            "  Step 2700/4330 - Loss: 1.1206\n",
            "  Step 2800/4330 - Loss: 0.5618\n",
            "  Step 2900/4330 - Loss: 1.0189\n",
            "  Step 3000/4330 - Loss: 0.4854\n",
            "  Step 3100/4330 - Loss: 0.7621\n",
            "  Step 3200/4330 - Loss: 0.1417\n",
            "  Step 3300/4330 - Loss: 0.2520\n",
            "  Step 3400/4330 - Loss: 0.2809\n",
            "  Step 3500/4330 - Loss: 0.7042\n",
            "  Step 3600/4330 - Loss: 0.4296\n",
            "  Step 3700/4330 - Loss: 1.3673\n",
            "  Step 3800/4330 - Loss: 0.1225\n",
            "  Step 3900/4330 - Loss: 0.1965\n",
            "  Step 4000/4330 - Loss: 0.5499\n",
            "  Step 4100/4330 - Loss: 0.7123\n",
            "  Step 4200/4330 - Loss: 0.3477\n",
            "  Step 4300/4330 - Loss: 0.6580\n",
            "Loss moyen entraînement : 0.5874\n",
            "Exact Match dev : 0.1170\n",
            "\n",
            "===== ÉPOCH 2/3 =====\n",
            "  Step 100/4330 - Loss: 0.2203\n",
            "  Step 200/4330 - Loss: 0.1887\n",
            "  Step 300/4330 - Loss: 0.1732\n",
            "  Step 400/4330 - Loss: 0.1277\n",
            "  Step 500/4330 - Loss: 0.1417\n",
            "  Step 600/4330 - Loss: 0.2747\n",
            "  Step 700/4330 - Loss: 0.3521\n",
            "  Step 800/4330 - Loss: 0.0947\n",
            "  Step 900/4330 - Loss: 0.1467\n",
            "  Step 1000/4330 - Loss: 0.3451\n",
            "  Step 1100/4330 - Loss: 0.1474\n",
            "  Step 1200/4330 - Loss: 0.3318\n",
            "  Step 1300/4330 - Loss: 0.1648\n",
            "  Step 1400/4330 - Loss: 0.5817\n",
            "  Step 1500/4330 - Loss: 0.1061\n",
            "  Step 1600/4330 - Loss: 0.2462\n",
            "  Step 1700/4330 - Loss: 0.1436\n",
            "  Step 1800/4330 - Loss: 0.1026\n",
            "  Step 1900/4330 - Loss: 0.6883\n",
            "  Step 2000/4330 - Loss: 0.2183\n",
            "  Step 2100/4330 - Loss: 0.3579\n",
            "  Step 2200/4330 - Loss: 0.1254\n",
            "  Step 2300/4330 - Loss: 0.5234\n",
            "  Step 2400/4330 - Loss: 0.2570\n",
            "  Step 2500/4330 - Loss: 0.2978\n",
            "  Step 2600/4330 - Loss: 0.2014\n",
            "  Step 2700/4330 - Loss: 0.4171\n",
            "  Step 2800/4330 - Loss: 0.3632\n",
            "  Step 2900/4330 - Loss: 0.1624\n",
            "  Step 3000/4330 - Loss: 0.2565\n",
            "  Step 3100/4330 - Loss: 0.1257\n",
            "  Step 3200/4330 - Loss: 0.2315\n",
            "  Step 3300/4330 - Loss: 0.3897\n",
            "  Step 3400/4330 - Loss: 0.3620\n",
            "  Step 3500/4330 - Loss: 0.2089\n",
            "  Step 3600/4330 - Loss: 0.2716\n",
            "  Step 3700/4330 - Loss: 0.2528\n",
            "  Step 3800/4330 - Loss: 0.2429\n",
            "  Step 3900/4330 - Loss: 0.4271\n",
            "  Step 4000/4330 - Loss: 0.2460\n",
            "  Step 4100/4330 - Loss: 0.1077\n",
            "  Step 4200/4330 - Loss: 0.0311\n",
            "  Step 4300/4330 - Loss: 0.0943\n",
            "Loss moyen entraînement : 0.2510\n",
            "Exact Match dev : 0.1219\n",
            "\n",
            "===== ÉPOCH 3/3 =====\n",
            "  Step 100/4330 - Loss: 0.1457\n",
            "  Step 200/4330 - Loss: 0.1292\n",
            "  Step 300/4330 - Loss: 0.1824\n",
            "  Step 400/4330 - Loss: 0.2190\n",
            "  Step 500/4330 - Loss: 0.2105\n",
            "  Step 600/4330 - Loss: 0.0942\n",
            "  Step 700/4330 - Loss: 0.1786\n",
            "  Step 800/4330 - Loss: 0.1526\n",
            "  Step 900/4330 - Loss: 0.0788\n",
            "  Step 1000/4330 - Loss: 0.5658\n",
            "  Step 1100/4330 - Loss: 0.2533\n",
            "  Step 1200/4330 - Loss: 0.1052\n",
            "  Step 1300/4330 - Loss: 0.0802\n",
            "  Step 1400/4330 - Loss: 0.1798\n",
            "  Step 1500/4330 - Loss: 0.0827\n",
            "  Step 1600/4330 - Loss: 0.1617\n",
            "  Step 1700/4330 - Loss: 0.1722\n",
            "  Step 1800/4330 - Loss: 0.2075\n",
            "  Step 1900/4330 - Loss: 0.1959\n",
            "  Step 2000/4330 - Loss: 0.1819\n",
            "  Step 2100/4330 - Loss: 0.1057\n",
            "  Step 2200/4330 - Loss: 0.1013\n",
            "  Step 2300/4330 - Loss: 0.1559\n",
            "  Step 2400/4330 - Loss: 0.0261\n",
            "  Step 2500/4330 - Loss: 0.0229\n",
            "  Step 2600/4330 - Loss: 0.1519\n",
            "  Step 2700/4330 - Loss: 0.2642\n",
            "  Step 2800/4330 - Loss: 0.3901\n",
            "  Step 2900/4330 - Loss: 0.0661\n",
            "  Step 3000/4330 - Loss: 0.2741\n",
            "  Step 3100/4330 - Loss: 0.2050\n",
            "  Step 3200/4330 - Loss: 0.0436\n",
            "  Step 3300/4330 - Loss: 0.0087\n",
            "  Step 3400/4330 - Loss: 0.0453\n",
            "  Step 3500/4330 - Loss: 0.1011\n",
            "  Step 3600/4330 - Loss: 0.3962\n",
            "  Step 3700/4330 - Loss: 0.1683\n",
            "  Step 3800/4330 - Loss: 0.0255\n",
            "  Step 3900/4330 - Loss: 0.3061\n",
            "  Step 4000/4330 - Loss: 0.1676\n",
            "  Step 4100/4330 - Loss: 0.3888\n",
            "  Step 4200/4330 - Loss: 0.0812\n",
            "  Step 4300/4330 - Loss: 0.0692\n",
            "Loss moyen entraînement : 0.1715\n",
            "Exact Match dev : 0.1103\n",
            "\n",
            "==============================\n",
            "  ENTRAÎNEMENT TERMINÉ\n",
            "==============================\n",
            "Temps total d'entraînement : 69.82 minutes\n",
            "                         = 4189.50 secondes\n",
            "==============================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()  # très important : mode évaluation\n",
        "\n",
        "def show_dev_example(idx, max_length=256):\n",
        "    \"\"\"\n",
        "    Affiche pour un exemple du dev set :\n",
        "      - l'input texte donné à BART\n",
        "      - le SQL généré par le modèle\n",
        "      - le SQL gold (cible)\n",
        "    \"\"\"\n",
        "    pair = dev_pairs[idx]\n",
        "    input_text = pair[\"input\"]\n",
        "    gold_sql   = pair[\"output\"]\n",
        "    db_id      = pair.get(\"db_id\", \"N/A\")\n",
        "\n",
        "    print(f\"===== EXEMPLE DEV #{idx} =====\")\n",
        "    print(f\"DB_ID : {db_id}\\n\")\n",
        "    print(\"----- INPUT BART -----\")\n",
        "    print(input_text)\n",
        "\n",
        "    # Préparation pour le modèle\n",
        "    inputs = tokenizer(\n",
        "        input_text,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        max_length=512\n",
        "    )\n",
        "\n",
        "    # Envoyer sur GPU si dispo\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "    # Génération\n",
        "    with torch.no_grad():\n",
        "        generated_ids = model.generate(\n",
        "            **inputs,\n",
        "            max_length=max_length,\n",
        "            num_beams=4,\n",
        "            early_stopping=True,\n",
        "        )\n",
        "\n",
        "    pred_sql = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    print(\"\\n----- SQL GÉNÉRÉ -----\")\n",
        "    print(pred_sql)\n",
        "\n",
        "    print(\"\\n----- SQL GOLD (Spider) -----\")\n",
        "    print(gold_sql)\n",
        "    print(\"=\"*60)\n"
      ],
      "metadata": {
        "id": "vAVxSzPnqe3a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_dev_example(0)\n",
        "show_dev_example(10)\n",
        "show_dev_example(25)\n",
        "show_dev_example(100)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0GtaR2Qqgee",
        "outputId": "84c7f99e-2eb4-4c37-95bf-90a13ca2d2ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== EXEMPLE DEV #0 =====\n",
            "DB_ID : concert_singer\n",
            "\n",
            "----- INPUT BART -----\n",
            "DB: concert_singer\n",
            "QUESTION: how many singers do we have\n",
            "\n",
            "TABLES:\n",
            "- stadium: stadium id, location, name, capacity, highest, lowest, average\n",
            "- singer: singer id, name, country, song name, song release year, age, is male\n",
            "- concert: concert id, concert name, theme, stadium id, year\n",
            "- singer in concert: concert id, singer id\n",
            "\n",
            "FOREIGN_KEYS:\n",
            "- concert.stadium id -> stadium.stadium id\n",
            "- singer in concert.singer id -> singer.singer id\n",
            "- singer in concert.concert id -> concert.concert id\n",
            "\n",
            "ENTITIES:\n",
            "- TABLE 'singers' -> singer\n",
            "\n",
            "\n",
            "----- SQL GÉNÉRÉ -----\n",
            "SELECT count(*) FROM singer\n",
            "\n",
            "----- SQL GOLD (Spider) -----\n",
            "SELECT count(*) FROM singer\n",
            "============================================================\n",
            "===== EXEMPLE DEV #10 =====\n",
            "DB_ID : concert_singer\n",
            "\n",
            "----- INPUT BART -----\n",
            "DB: concert_singer\n",
            "QUESTION: show all countries and the number of singers in each country\n",
            "\n",
            "TABLES:\n",
            "- stadium: stadium id, location, name, capacity, highest, lowest, average\n",
            "- singer: singer id, name, country, song name, song release year, age, is male\n",
            "- concert: concert id, concert name, theme, stadium id, year\n",
            "- singer in concert: concert id, singer id\n",
            "\n",
            "FOREIGN_KEYS:\n",
            "- concert.stadium id -> stadium.stadium id\n",
            "- singer in concert.singer id -> singer.singer id\n",
            "- singer in concert.concert id -> concert.concert id\n",
            "\n",
            "ENTITIES:\n",
            "- COLUMN 'countries' -> singer.country\n",
            "- TABLE 'singers' -> singer\n",
            "- COLUMN 'country' -> singer.country\n",
            "\n",
            "\n",
            "----- SQL GÉNÉRÉ -----\n",
            "SELECT Country,  COUNT(*) FROM singer GROUP BY Country\n",
            "\n",
            "----- SQL GOLD (Spider) -----\n",
            "SELECT country ,  count(*) FROM singer GROUP BY country\n",
            "============================================================\n",
            "===== EXEMPLE DEV #25 =====\n",
            "DB_ID : concert_singer\n",
            "\n",
            "----- INPUT BART -----\n",
            "DB: concert_singer\n",
            "QUESTION: what is the name and capacity of the stadium with the most concerts after 2013\n",
            "\n",
            "TABLES:\n",
            "- stadium: stadium id, location, name, capacity, highest, lowest, average\n",
            "- singer: singer id, name, country, song name, song release year, age, is male\n",
            "- concert: concert id, concert name, theme, stadium id, year\n",
            "- singer in concert: concert id, singer id\n",
            "\n",
            "FOREIGN_KEYS:\n",
            "- concert.stadium id -> stadium.stadium id\n",
            "- singer in concert.singer id -> singer.singer id\n",
            "- singer in concert.concert id -> concert.concert id\n",
            "\n",
            "ENTITIES:\n",
            "- VALUE '2013' -> None\n",
            "- COLUMN 'name' -> concert.concert name\n",
            "- COLUMN 'capacity' -> stadium.capacity\n",
            "- TABLE 'stadium' -> stadium\n",
            "- TABLE 'concerts' -> concert\n",
            "\n",
            "\n",
            "----- SQL GÉNÉRÉ -----\n",
            "SELECT T2.name,  T2.'capacity FROM stadium AS T1 JOIN concert AS T2 ON T1.Stadium_ID  =  T 2.Stuid WHERE YEAR  >  2013 GROUP BY T3.StuID ORDER BY COUNT(*) DESC LIMIT 1\n",
            "\n",
            "----- SQL GOLD (Spider) -----\n",
            "SELECT T2.name ,  T2.capacity FROM concert AS T1 JOIN stadium AS T2 ON T1.stadium_id  =  T2.stadium_id WHERE T1.year  >=  2014 GROUP BY T2.stadium_id ORDER BY count(*) DESC LIMIT 1\n",
            "============================================================\n",
            "===== EXEMPLE DEV #100 =====\n",
            "DB_ID : car_1\n",
            "\n",
            "----- INPUT BART -----\n",
            "DB: car_1\n",
            "QUESTION: what is the name of the different car makers who produced a car in 1970\n",
            "\n",
            "TABLES:\n",
            "- continents: cont id, continent\n",
            "- countries: country id, country name, continent\n",
            "- car makers: id, maker, full name, country\n",
            "- model list: model id, maker, model\n",
            "- car names: make id, model, make\n",
            "- cars data: id, mpg, cylinders, edispl, horsepower, weight, accelerate, year\n",
            "\n",
            "FOREIGN_KEYS:\n",
            "- countries.continent -> continents.cont id\n",
            "- car makers.country -> countries.country id\n",
            "- model list.maker -> car makers.id\n",
            "- car names.model -> model list.model\n",
            "- cars data.id -> car names.make id\n",
            "\n",
            "ENTITIES:\n",
            "- VALUE '1970' -> None\n",
            "- COLUMN 'name' -> car makers.full name\n",
            "- COLUMN 'makers' -> model list.maker\n",
            "\n",
            "\n",
            "----- SQL GÉNÉRÉ -----\n",
            "SELECT DISTINCT T1.name FROM car_profiles AS T1 JOIN model_outcomes AS T2 ON T2.Model  =  T3.ID JOIN car_locations AS T3 ON T1!id  = BETWEEN 1970 AND 1970\n",
            "\n",
            "----- SQL GOLD (Spider) -----\n",
            "SELECT DISTINCT T1.Maker FROM CAR_MAKERS AS T1 JOIN MODEL_LIST AS T2 ON T1.Id  =  T2.Maker JOIN CAR_NAMES AS T3 ON T2.model  =  T3.model JOIN CARS_DATA AS T4 ON T3.MakeId  =  T4.id WHERE T4.year  =  '1970';\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Au terme de trois époques de fine-tuning, la loss d’entraînement diminue fortement (0.58 → 0.17), ce qui montre que BART-base apprend efficacement les correspondances entre questions en langage naturel et requêtes SQL.\n",
        "\n",
        "L’Exact Match mesuré sur le jeu de validation atteint un maximum de 12.19 % à l’epoch 2.\n",
        "\n",
        "Bien que l’Exact Match puisse paraître faible, ce niveau de performance est cohérent avec les résultats connus des modèles seq2seq de taille modérée sur Spider. L’Exact Match est une métrique très stricte qui exige une égalité textuelle parfaite de la requête SQL, même lorsque la prédiction est logiquement équivalente.\n",
        "\n",
        "Compte tenu du modèle utilisé (BART-base, 140M paramètres), du nombre limité d’époques, et de la complexité du dataset Spider (requêtes multi-tables, sous-requêtes, agrégations), ces résultats sont attendus et validés dans la littérature. Ils montrent que la pipeline proposée permet au modèle d’apprendre les requêtes simples et moyennes, tout en révélant les limites inhérentes aux architectures seq2seq généralistes appliquées au Text-to-SQL."
      ],
      "metadata": {
        "id": "K2Iw1SLboh6E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "save_dir = \"./bart_text2sql_final\"\n",
        "model.save_pretrained(save_dir)\n",
        "tokenizer.save_pretrained(save_dir)\n",
        "print(\"Modèle et tokenizer sauvegardés dans\", save_dir)\n"
      ],
      "metadata": {
        "id": "Mw9Ze-0pi0wW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66f99b43-ade3-41d1-d148-de16c68e421a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modèle et tokenizer sauvegardés dans ./bart_text2sql_final\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "To6lejJDuduY"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "96a629cf6f7340ae91c8c6f0adae94e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8ca94892cb9f4c63b27db250f428d8e0",
              "IPY_MODEL_1fb00f03c2ba4829af4f41254d15e1aa",
              "IPY_MODEL_c5741689b5074a97a09868237ce40af3"
            ],
            "layout": "IPY_MODEL_af464c4e2c5e4a43a1443588f713ef7f"
          }
        },
        "8ca94892cb9f4c63b27db250f428d8e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22a35d8ec9e24cd1a263e388ce26db18",
            "placeholder": "​",
            "style": "IPY_MODEL_e55fc1fe85334cf1b179f0e3467b8b7b",
            "value": ""
          }
        },
        "1fb00f03c2ba4829af4f41254d15e1aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5067ea71ac3a4ceface7747a3c66ff4f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6a73c9cd1c174834962bbeecf85fb568",
            "value": 0
          }
        },
        "c5741689b5074a97a09868237ce40af3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_170229f5b24d45b0be410500f4b17a41",
            "placeholder": "​",
            "style": "IPY_MODEL_c4fe33e4955a4c60b818b571def0cc8a",
            "value": " 0/0 [00:00&lt;?, ?it/s]"
          }
        },
        "af464c4e2c5e4a43a1443588f713ef7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22a35d8ec9e24cd1a263e388ce26db18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e55fc1fe85334cf1b179f0e3467b8b7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5067ea71ac3a4ceface7747a3c66ff4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "6a73c9cd1c174834962bbeecf85fb568": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "170229f5b24d45b0be410500f4b17a41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4fe33e4955a4c60b818b571def0cc8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "61c50453f1754a95a4ea429f2a6efba1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_db5b8cc435ff43e69f072228c8cd926e",
              "IPY_MODEL_ab79fa562b494d9c9ea4962ab4586e48",
              "IPY_MODEL_3322f42c126f4985b4fe5b6aec831b1e"
            ],
            "layout": "IPY_MODEL_990bb816181e47998ee36f170b04bfae"
          }
        },
        "db5b8cc435ff43e69f072228c8cd926e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ca8cd492666424c894f4dff8775884c",
            "placeholder": "​",
            "style": "IPY_MODEL_be34db09033246b48fc2991cb31a9402",
            "value": "model.safetensors: 100%"
          }
        },
        "ab79fa562b494d9c9ea4962ab4586e48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9f677fdc3e0496bbfac13b14a50839e",
            "max": 557709915,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b620ac99fda34c5e9711d661be4294d4",
            "value": 557709915
          }
        },
        "3322f42c126f4985b4fe5b6aec831b1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9afe720fc5746898183c70240db1b76",
            "placeholder": "​",
            "style": "IPY_MODEL_dc99795cde514c7a960d4f5be443ae73",
            "value": " 558M/558M [00:03&lt;00:00, 283MB/s]"
          }
        },
        "990bb816181e47998ee36f170b04bfae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ca8cd492666424c894f4dff8775884c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be34db09033246b48fc2991cb31a9402": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b9f677fdc3e0496bbfac13b14a50839e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b620ac99fda34c5e9711d661be4294d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f9afe720fc5746898183c70240db1b76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc99795cde514c7a960d4f5be443ae73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}