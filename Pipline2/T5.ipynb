{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3lbJL-nxY5f",
        "outputId": "7b12afea-6153-43d4-d2ed-d7ef125484a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: transformers 4.57.3\n",
            "Uninstalling transformers-4.57.3:\n",
            "  Successfully uninstalled transformers-4.57.3\n",
            "\u001b[33mWARNING: Skipping optimum-quanto as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mFound existing installation: accelerate 1.12.0\n",
            "Uninstalling accelerate-1.12.0:\n",
            "  Successfully uninstalled accelerate-1.12.0\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall -y transformers optimum-quanto accelerate\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"transformers==4.44.2\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RqiWfXN8xeHg",
        "outputId": "4fe96c6c-1293-4427-cadf-f99b35d03f16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==4.44.2\n",
            "  Downloading transformers-4.44.2-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (2.32.4)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (0.7.0)\n",
            "Collecting tokenizers<0.20,>=0.19 (from transformers==4.44.2)\n",
            "  Downloading tokenizers-0.19.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers==4.44.2) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.44.2) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.44.2) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.44.2) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.44.2) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.44.2) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.44.2) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.44.2) (2025.11.12)\n",
            "Downloading transformers-4.44.2-py3-none-any.whl (9.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m93.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.19.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m96.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.22.1\n",
            "    Uninstalling tokenizers-0.22.1:\n",
            "      Successfully uninstalled tokenizers-0.22.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "peft 0.18.0 requires accelerate>=0.21.0, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tokenizers-0.19.1 transformers-4.44.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import time\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n"
      ],
      "metadata": {
        "id": "GNkTCSQwyBvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Charger les paires préparées\n",
        "with open(\"/content/bart_train_pairsfinal.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    train_pairs = json.load(f)\n",
        "\n",
        "with open(\"/content/bart_dev_pairsfinal.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    dev_pairs = json.load(f)\n",
        "\n",
        "print(\"Train size:\", len(train_pairs))\n",
        "print(\"Dev size  :\", len(dev_pairs))\n",
        "\n",
        "\n",
        "# 2) Dataset pour BART\n",
        "class Text2SQLDataset(Dataset):\n",
        "    def __init__(self, pairs, tokenizer, max_input_len=512, max_output_len=256):\n",
        "        self.pairs = pairs\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_input_len = max_input_len\n",
        "        self.max_output_len = max_output_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.pairs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.pairs[idx]\n",
        "\n",
        "        enc = self.tokenizer(\n",
        "            item[\"input\"],\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=self.max_input_len,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "\n",
        "        dec = self.tokenizer(\n",
        "            item[\"output\"],\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=self.max_output_len,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": enc[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": enc[\"attention_mask\"].squeeze(0),\n",
        "            \"labels\": dec[\"input_ids\"].squeeze(0),\n",
        "        }\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7OXNcEEqxhEm",
        "outputId": "645b8e68-710f-42af-ca57-eeb7abcd8995"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 8659\n",
            "Dev size  : 1034\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Charger T5-small + tokenizer\n",
        "model_name = \"t5-small\"\n",
        "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "# IMPORTANT : bien régler pad_token_id (sinon erreurs de loss parfois)\n",
        "model.config.pad_token_id = tokenizer.pad_token_id\n",
        "model.config.eos_token_id = tokenizer.eos_token_id\n",
        "\n",
        "# Device (GPU si dispo)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "print(\"Device :\", device)\n",
        "\n",
        "# 2) Créer les Dataset / DataLoader\n",
        "train_dataset = Text2SQLDataset(train_pairs, tokenizer)\n",
        "val_dataset   = Text2SQLDataset(dev_pairs, tokenizer)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
        "val_loader   = DataLoader(val_dataset, batch_size=4, shuffle=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TEjOoqXcxq17",
        "outputId": "d7e68bb6-8922-4ece-a1ad-efb440c7a61e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device : cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_exact_match(pred_texts, label_texts):\n",
        "    pred_texts = [p.strip().lower() for p in pred_texts]\n",
        "    label_texts = [l.strip().lower() for l in label_texts]\n",
        "    matches = [int(p == l) for p, l in zip(pred_texts, label_texts)]\n",
        "    return sum(matches) / len(matches) if matches else 0.0\n",
        "\n",
        "num_epochs = 3   # commence par 1 ou 2 pour tester, après tu peux mettre 3\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "pad_token_id = tokenizer.pad_token_id\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    print(f\"\\n===== ÉPOCH {epoch}/{num_epochs} =====\")\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for step, batch in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        input_ids      = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        labels         = batch[\"labels\"].to(device)\n",
        "\n",
        "        # Ignorer le padding dans la loss\n",
        "        labels_for_loss = labels.clone()\n",
        "        labels_for_loss[labels_for_loss == pad_token_id] = -100\n",
        "\n",
        "        outputs = model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            labels=labels_for_loss,\n",
        "        )\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        if (step + 1) % 500 == 0:\n",
        "            print(f\"  Step {step+1}/{len(train_loader)} - Loss: {loss.item():.4f}\")\n",
        "\n",
        "    avg_train_loss = total_loss / len(train_loader)\n",
        "    print(f\"Loss moyen entraînement : {avg_train_loss:.4f}\")\n",
        "\n",
        "    # ========= ÉVALUATION =========\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels_text = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            input_ids      = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            labels         = batch[\"labels\"].to(device)\n",
        "\n",
        "            # Génération de la prédiction\n",
        "            generated_ids = model.generate(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                max_length=256,\n",
        "                num_beams=4,\n",
        "            )\n",
        "\n",
        "            pred_texts = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
        "\n",
        "            # Texte de référence\n",
        "            label_texts = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "            all_preds.extend(pred_texts)\n",
        "            all_labels_text.extend(label_texts)\n",
        "\n",
        "    exact_match = compute_exact_match(all_preds, all_labels_text)\n",
        "    print(f\"Exact Match dev : {exact_match:.4f}\")\n",
        "\n",
        "end_time = time.time()\n",
        "training_duration = end_time - start_time\n",
        "print(\"\\n==============================\")\n",
        "print(\"  ENTRAÎNEMENT TERMINÉ\")\n",
        "print(\"==============================\")\n",
        "print(f\"Temps total d'entraînement : {training_duration/60:.2f} minutes\")\n",
        "print(f\"                         = {training_duration:.2f} secondes\")\n",
        "print(\"==============================\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XdGd7obqxrSV",
        "outputId": "0f936e09-9c8e-41f6-e080-b4595497ca40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== ÉPOCH 1/3 =====\n",
            "  Step 500/4330 - Loss: 1.9375\n",
            "  Step 1000/4330 - Loss: 0.6897\n",
            "  Step 1500/4330 - Loss: 1.0437\n",
            "  Step 2000/4330 - Loss: 0.8351\n",
            "  Step 2500/4330 - Loss: 1.4498\n",
            "  Step 3000/4330 - Loss: 0.6293\n",
            "  Step 3500/4330 - Loss: 0.6679\n",
            "  Step 4000/4330 - Loss: 0.7673\n",
            "Loss moyen entraînement : 1.1253\n",
            "Exact Match dev : 0.0580\n",
            "\n",
            "===== ÉPOCH 2/3 =====\n",
            "  Step 500/4330 - Loss: 0.3741\n",
            "  Step 1000/4330 - Loss: 0.9603\n",
            "  Step 1500/4330 - Loss: 0.2762\n",
            "  Step 2000/4330 - Loss: 0.6203\n",
            "  Step 2500/4330 - Loss: 0.2882\n",
            "  Step 3000/4330 - Loss: 0.2996\n",
            "  Step 3500/4330 - Loss: 0.4034\n",
            "  Step 4000/4330 - Loss: 0.1742\n",
            "Loss moyen entraînement : 0.5530\n",
            "Exact Match dev : 0.1489\n",
            "\n",
            "===== ÉPOCH 3/3 =====\n",
            "  Step 500/4330 - Loss: 0.3949\n",
            "  Step 1000/4330 - Loss: 0.3600\n",
            "  Step 1500/4330 - Loss: 0.1634\n",
            "  Step 2000/4330 - Loss: 0.5782\n",
            "  Step 2500/4330 - Loss: 0.6786\n",
            "  Step 3000/4330 - Loss: 0.2752\n",
            "  Step 3500/4330 - Loss: 0.2366\n",
            "  Step 4000/4330 - Loss: 0.4430\n",
            "Loss moyen entraînement : 0.4040\n",
            "Exact Match dev : 0.1663\n",
            "\n",
            "==============================\n",
            "  ENTRAÎNEMENT TERMINÉ\n",
            "==============================\n",
            "Temps total d'entraînement : 42.20 minutes\n",
            "                         = 2531.86 secondes\n",
            "==============================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "def show_dev_example(idx, max_length=256):\n",
        "    pair = dev_pairs[idx]\n",
        "    input_text = pair[\"input\"]\n",
        "    gold_sql   = pair[\"output\"]\n",
        "    db_id      = pair.get(\"db_id\", \"N/A\")\n",
        "\n",
        "    print(f\"===== EXEMPLE DEV #{idx} =====\")\n",
        "    print(f\"DB_ID : {db_id}\\n\")\n",
        "    print(\"----- INPUT T5 -----\")\n",
        "    print(input_text)\n",
        "\n",
        "    inputs = tokenizer(\n",
        "        input_text,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        max_length=512\n",
        "    )\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        generated_ids = model.generate(\n",
        "            **inputs,\n",
        "            max_length=max_length,\n",
        "            num_beams=4,\n",
        "            early_stopping=True,\n",
        "        )\n",
        "\n",
        "    pred_sql = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    print(\"\\n----- SQL GÉNÉRÉ -----\")\n",
        "    print(pred_sql)\n",
        "\n",
        "    print(\"\\n----- SQL GOLD (Spider) -----\")\n",
        "    print(gold_sql)\n",
        "    print(\"=\"*60)\n"
      ],
      "metadata": {
        "id": "Jt9VhVLWxvOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_dev_example(0)\n",
        "show_dev_example(10)\n",
        "show_dev_example(25)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRp8ugZmxvuj",
        "outputId": "8299fc17-e43b-440e-b4c0-687e50e33f1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== EXEMPLE DEV #0 =====\n",
            "DB_ID : concert_singer\n",
            "\n",
            "----- INPUT T5 -----\n",
            "DB: concert_singer\n",
            "QUESTION: how many singers do we have\n",
            "\n",
            "TABLES:\n",
            "- stadium: stadium id, location, name, capacity, highest, lowest, average\n",
            "- singer: singer id, name, country, song name, song release year, age, is male\n",
            "- concert: concert id, concert name, theme, stadium id, year\n",
            "- singer in concert: concert id, singer id\n",
            "\n",
            "FOREIGN_KEYS:\n",
            "- concert.stadium id -> stadium.stadium id\n",
            "- singer in concert.singer id -> singer.singer id\n",
            "- singer in concert.concert id -> concert.concert id\n",
            "\n",
            "ENTITIES:\n",
            "- TABLE 'singers' -> singer\n",
            "\n",
            "\n",
            "----- SQL GÉNÉRÉ -----\n",
            "SELECT count(*) FROM singer\n",
            "\n",
            "----- SQL GOLD (Spider) -----\n",
            "SELECT count(*) FROM singer\n",
            "============================================================\n",
            "===== EXEMPLE DEV #10 =====\n",
            "DB_ID : concert_singer\n",
            "\n",
            "----- INPUT T5 -----\n",
            "DB: concert_singer\n",
            "QUESTION: show all countries and the number of singers in each country\n",
            "\n",
            "TABLES:\n",
            "- stadium: stadium id, location, name, capacity, highest, lowest, average\n",
            "- singer: singer id, name, country, song name, song release year, age, is male\n",
            "- concert: concert id, concert name, theme, stadium id, year\n",
            "- singer in concert: concert id, singer id\n",
            "\n",
            "FOREIGN_KEYS:\n",
            "- concert.stadium id -> stadium.stadium id\n",
            "- singer in concert.singer id -> singer.singer id\n",
            "- singer in concert.concert id -> concert.concert id\n",
            "\n",
            "ENTITIES:\n",
            "- COLUMN 'countries' -> singer.country\n",
            "- TABLE 'singers' -> singer\n",
            "- COLUMN 'country' -> singer.country\n",
            "\n",
            "\n",
            "----- SQL GÉNÉRÉ -----\n",
            "SELECT country, count(*) FROM singer GROUP BY country\n",
            "\n",
            "----- SQL GOLD (Spider) -----\n",
            "SELECT country ,  count(*) FROM singer GROUP BY country\n",
            "============================================================\n",
            "===== EXEMPLE DEV #25 =====\n",
            "DB_ID : concert_singer\n",
            "\n",
            "----- INPUT T5 -----\n",
            "DB: concert_singer\n",
            "QUESTION: what is the name and capacity of the stadium with the most concerts after 2013\n",
            "\n",
            "TABLES:\n",
            "- stadium: stadium id, location, name, capacity, highest, lowest, average\n",
            "- singer: singer id, name, country, song name, song release year, age, is male\n",
            "- concert: concert id, concert name, theme, stadium id, year\n",
            "- singer in concert: concert id, singer id\n",
            "\n",
            "FOREIGN_KEYS:\n",
            "- concert.stadium id -> stadium.stadium id\n",
            "- singer in concert.singer id -> singer.singer id\n",
            "- singer in concert.concert id -> concert.concert id\n",
            "\n",
            "ENTITIES:\n",
            "- VALUE '2013' -> None\n",
            "- COLUMN 'name' -> concert.concert name\n",
            "- COLUMN 'capacity' -> stadium.capacity\n",
            "- TABLE 'stadium' -> stadium\n",
            "- TABLE 'concerts' -> concert\n",
            "\n",
            "\n",
            "----- SQL GÉNÉRÉ -----\n",
            "SELECT T1.name, T2.capacity FROM stadium AS T1 JOIN concert AS T2 ON T1.stadium_id = T2.stadium_id GROUP BY T1.stadium_id ORDER BY count(*) DESC LIMIT 1\n",
            "\n",
            "----- SQL GOLD (Spider) -----\n",
            "SELECT T2.name ,  T2.capacity FROM concert AS T1 JOIN stadium AS T2 ON T1.stadium_id  =  T2.stadium_id WHERE T1.year  >=  2014 GROUP BY T2.stadium_id ORDER BY count(*) DESC LIMIT 1\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "“Avec T5-small, la loss d'entraînement diminue de 1.12 à 0.40 en trois époques, ce qui montre une bonne capacité d’apprentissage.\n",
        "L’Exact Match sur le jeu de validation augmente de manière monotone, de 5.8 % à 16.6 %, ce qui indique que le modèle généralise mieux que BART-base dans notre configuration expérimentale.\n",
        "\n",
        "Malgré un score qui reste modeste au regard des modèles d’état de l’art sur Spider, ce résultat est cohérent avec la taille du modèle (T5-small), les ressources matérielles limitées (un seul GPU Colab) et la difficulté du benchmark.”"
      ],
      "metadata": {
        "id": "Z1Oo0Moi_VyP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_dir = \"/content/t5_small_text2sql_finetuned\"\n",
        "\n",
        "model.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "print(\"Modèle T5-small et tokenizer sauvegardés dans\", output_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBD7ZD1e_SPT",
        "outputId": "de00a27a-4206-4c62-eac6-67034160bfa0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modèle T5-small et tokenizer sauvegardés dans /content/t5_small_text2sql_finetuned\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# On continue l'entraînement à partir de l'état actuel du modèle\n",
        "extra_epochs = 2          # par exemple : encore 2 epochs (4 et 5)\n",
        "start_epoch = 3           # tu as déjà fait 3 epochs\n",
        "pad_token_id = tokenizer.pad_token_id\n",
        "\n",
        "for epoch in range(start_epoch + 1, start_epoch + 1 + extra_epochs):\n",
        "    print(f\"\\n===== ÉPOCH {epoch}/{start_epoch + extra_epochs} (CONTINUATION) =====\")\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for step, batch in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        input_ids      = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        labels         = batch[\"labels\"].to(device)\n",
        "\n",
        "        labels_for_loss = labels.clone()\n",
        "        labels_for_loss[labels_for_loss == pad_token_id] = -100\n",
        "\n",
        "        outputs = model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            labels=labels_for_loss,\n",
        "        )\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        if (step + 1) % 500 == 0:\n",
        "            print(f\"  Step {step+1}/{len(train_loader)} - Loss: {loss.item():.4f}\")\n",
        "\n",
        "    avg_train_loss = total_loss / len(train_loader)\n",
        "    print(f\"Loss moyen entraînement (epoch {epoch}) : {avg_train_loss:.4f}\")\n",
        "\n",
        "    # ====== ÉVAL DEV ======\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels_text = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            input_ids      = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            labels         = batch[\"labels\"].to(device)\n",
        "\n",
        "            generated_ids = model.generate(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                max_length=256,\n",
        "                num_beams=4,\n",
        "            )\n",
        "\n",
        "            pred_texts = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
        "            label_texts = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "            all_preds.extend(pred_texts)\n",
        "            all_labels_text.extend(label_texts)\n",
        "\n",
        "    exact_match = compute_exact_match(all_preds, all_labels_text)\n",
        "    print(f\"Exact Match dev (epoch {epoch}) : {exact_match:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m03znOD8_jCo",
        "outputId": "a6779631-9e05-4a0e-9520-e9f4c878621a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== ÉPOCH 4/5 (CONTINUATION) =====\n",
            "  Step 500/4330 - Loss: 0.5954\n",
            "  Step 1000/4330 - Loss: 0.0899\n",
            "  Step 1500/4330 - Loss: 0.2190\n",
            "  Step 2000/4330 - Loss: 0.2122\n",
            "  Step 2500/4330 - Loss: 0.5448\n",
            "  Step 3000/4330 - Loss: 0.3613\n",
            "  Step 3500/4330 - Loss: 0.1303\n",
            "  Step 4000/4330 - Loss: 0.2580\n",
            "Loss moyen entraînement (epoch 4) : 0.3260\n",
            "Exact Match dev (epoch 4) : 0.1692\n",
            "\n",
            "===== ÉPOCH 5/5 (CONTINUATION) =====\n",
            "  Step 500/4330 - Loss: 0.2008\n",
            "  Step 1000/4330 - Loss: 0.4557\n",
            "  Step 1500/4330 - Loss: 0.3844\n",
            "  Step 2000/4330 - Loss: 0.3646\n",
            "  Step 2500/4330 - Loss: 0.3186\n",
            "  Step 3000/4330 - Loss: 0.2226\n",
            "  Step 3500/4330 - Loss: 0.2245\n",
            "  Step 4000/4330 - Loss: 0.0297\n",
            "Loss moyen entraînement (epoch 5) : 0.2712\n",
            "Exact Match dev (epoch 5) : 0.1867\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Chemin où tu veux sauvegarder le modèle\n",
        "output_dir = \"/content/t5_small_text2sql_5epochs\"\n",
        "\n",
        "model.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "print(\"✅ Modèle et tokenizer T5-small sauvegardés dans :\", output_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CAg1o6EjKbD7",
        "outputId": "d1a9daf5-4777-4a3b-df04-f0dd3933c3aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Modèle et tokenizer T5-small sauvegardés dans : /content/t5_small_text2sql_5epochs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()  # important\n",
        "\n",
        "def show_dev_example(idx, max_length=256):\n",
        "    \"\"\"\n",
        "    Affiche pour un exemple du dev set :\n",
        "      - l'input texte (question + schéma)\n",
        "      - le SQL généré par le modèle\n",
        "      - le SQL gold (Spider)\n",
        "    \"\"\"\n",
        "    pair = dev_pairs[idx]\n",
        "    input_text = pair[\"input\"]\n",
        "    gold_sql   = pair[\"output\"]\n",
        "    db_id      = pair.get(\"db_id\", \"N/A\")\n",
        "\n",
        "    print(f\"===== EXEMPLE DEV #{idx} =====\")\n",
        "    print(f\"DB_ID : {db_id}\\n\")\n",
        "\n",
        "    print(\"----- INPUT T5 -----\")\n",
        "    print(input_text)\n",
        "\n",
        "    # Préparation input pour le modèle\n",
        "    inputs = tokenizer(\n",
        "        input_text,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        max_length=512,\n",
        "    )\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "    # Génération\n",
        "    with torch.no_grad():\n",
        "        generated_ids = model.generate(\n",
        "            **inputs,\n",
        "            max_length=max_length,\n",
        "            num_beams=4,\n",
        "            early_stopping=True,\n",
        "        )\n",
        "\n",
        "    pred_sql = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    print(\"\\n----- SQL GÉNÉRÉ -----\")\n",
        "    print(pred_sql)\n",
        "\n",
        "    print(\"\\n----- SQL GOLD (Spider) -----\")\n",
        "    print(gold_sql)\n",
        "    print(\"=\"*70)\n"
      ],
      "metadata": {
        "id": "0RcIeprYKcxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_dev_example(0)\n",
        "show_dev_example(10)\n",
        "show_dev_example(25)\n",
        "show_dev_example(100)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIr-jd25Kvr9",
        "outputId": "e79af54c-ed2c-4a88-bd9e-ae58275f0346"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== EXEMPLE DEV #0 =====\n",
            "DB_ID : concert_singer\n",
            "\n",
            "----- INPUT T5 -----\n",
            "DB: concert_singer\n",
            "QUESTION: how many singers do we have\n",
            "\n",
            "TABLES:\n",
            "- stadium: stadium id, location, name, capacity, highest, lowest, average\n",
            "- singer: singer id, name, country, song name, song release year, age, is male\n",
            "- concert: concert id, concert name, theme, stadium id, year\n",
            "- singer in concert: concert id, singer id\n",
            "\n",
            "FOREIGN_KEYS:\n",
            "- concert.stadium id -> stadium.stadium id\n",
            "- singer in concert.singer id -> singer.singer id\n",
            "- singer in concert.concert id -> concert.concert id\n",
            "\n",
            "ENTITIES:\n",
            "- TABLE 'singers' -> singer\n",
            "\n",
            "\n",
            "----- SQL GÉNÉRÉ -----\n",
            "SELECT count(*) FROM singer\n",
            "\n",
            "----- SQL GOLD (Spider) -----\n",
            "SELECT count(*) FROM singer\n",
            "======================================================================\n",
            "===== EXEMPLE DEV #10 =====\n",
            "DB_ID : concert_singer\n",
            "\n",
            "----- INPUT T5 -----\n",
            "DB: concert_singer\n",
            "QUESTION: show all countries and the number of singers in each country\n",
            "\n",
            "TABLES:\n",
            "- stadium: stadium id, location, name, capacity, highest, lowest, average\n",
            "- singer: singer id, name, country, song name, song release year, age, is male\n",
            "- concert: concert id, concert name, theme, stadium id, year\n",
            "- singer in concert: concert id, singer id\n",
            "\n",
            "FOREIGN_KEYS:\n",
            "- concert.stadium id -> stadium.stadium id\n",
            "- singer in concert.singer id -> singer.singer id\n",
            "- singer in concert.concert id -> concert.concert id\n",
            "\n",
            "ENTITIES:\n",
            "- COLUMN 'countries' -> singer.country\n",
            "- TABLE 'singers' -> singer\n",
            "- COLUMN 'country' -> singer.country\n",
            "\n",
            "\n",
            "----- SQL GÉNÉRÉ -----\n",
            "SELECT Country, count(*) FROM singer GROUP BY Country\n",
            "\n",
            "----- SQL GOLD (Spider) -----\n",
            "SELECT country ,  count(*) FROM singer GROUP BY country\n",
            "======================================================================\n",
            "===== EXEMPLE DEV #25 =====\n",
            "DB_ID : concert_singer\n",
            "\n",
            "----- INPUT T5 -----\n",
            "DB: concert_singer\n",
            "QUESTION: what is the name and capacity of the stadium with the most concerts after 2013\n",
            "\n",
            "TABLES:\n",
            "- stadium: stadium id, location, name, capacity, highest, lowest, average\n",
            "- singer: singer id, name, country, song name, song release year, age, is male\n",
            "- concert: concert id, concert name, theme, stadium id, year\n",
            "- singer in concert: concert id, singer id\n",
            "\n",
            "FOREIGN_KEYS:\n",
            "- concert.stadium id -> stadium.stadium id\n",
            "- singer in concert.singer id -> singer.singer id\n",
            "- singer in concert.concert id -> concert.concert id\n",
            "\n",
            "ENTITIES:\n",
            "- VALUE '2013' -> None\n",
            "- COLUMN 'name' -> concert.concert name\n",
            "- COLUMN 'capacity' -> stadium.capacity\n",
            "- TABLE 'stadium' -> stadium\n",
            "- TABLE 'concerts' -> concert\n",
            "\n",
            "\n",
            "----- SQL GÉNÉRÉ -----\n",
            "SELECT name, capacity FROM stadium ORDER BY capacity DESC LIMIT 1\n",
            "\n",
            "----- SQL GOLD (Spider) -----\n",
            "SELECT T2.name ,  T2.capacity FROM concert AS T1 JOIN stadium AS T2 ON T1.stadium_id  =  T2.stadium_id WHERE T1.year  >=  2014 GROUP BY T2.stadium_id ORDER BY count(*) DESC LIMIT 1\n",
            "======================================================================\n",
            "===== EXEMPLE DEV #100 =====\n",
            "DB_ID : car_1\n",
            "\n",
            "----- INPUT T5 -----\n",
            "DB: car_1\n",
            "QUESTION: what is the name of the different car makers who produced a car in 1970\n",
            "\n",
            "TABLES:\n",
            "- continents: cont id, continent\n",
            "- countries: country id, country name, continent\n",
            "- car makers: id, maker, full name, country\n",
            "- model list: model id, maker, model\n",
            "- car names: make id, model, make\n",
            "- cars data: id, mpg, cylinders, edispl, horsepower, weight, accelerate, year\n",
            "\n",
            "FOREIGN_KEYS:\n",
            "- countries.continent -> continents.cont id\n",
            "- car makers.country -> countries.country id\n",
            "- model list.maker -> car makers.id\n",
            "- car names.model -> model list.model\n",
            "- cars data.id -> car names.make id\n",
            "\n",
            "ENTITIES:\n",
            "- VALUE '1970' -> None\n",
            "- COLUMN 'name' -> car makers.full name\n",
            "- COLUMN 'makers' -> model list.maker\n",
            "\n",
            "\n",
            "----- SQL GÉNÉRÉ -----\n",
            "SELECT DISTINCT maker FROM Car_Makers WHERE YEAR = 1970\n",
            "\n",
            "----- SQL GOLD (Spider) -----\n",
            "SELECT DISTINCT T1.Maker FROM CAR_MAKERS AS T1 JOIN MODEL_LIST AS T2 ON T1.Id  =  T2.Maker JOIN CAR_NAMES AS T3 ON T2.model  =  T3.model JOIN CARS_DATA AS T4 ON T3.MakeId  =  T4.id WHERE T4.year  =  '1970';\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "“En augmentant le nombre d’époques d’entraînement de 3 à 5 pour T5-small, nous observons une amélioration progressive de l’Exact Match sur le jeu de validation, qui passe de 16.6 % à 18.7 %. La loss d’entraînement continue de diminuer, ce qui suggère que le modèle n’a pas encore atteint un sur-apprentissage fort, même si les gains deviennent de plus en plus marginaux. Ces résultats montrent que T5-small exploite mieux notre pipeline schema-aware que BART-base, tout en restant limité par la taille du modèle et la complexité du benchmark Spider.”"
      ],
      "metadata": {
        "id": "YjrdP3SJLfg4"
      }
    }
  ]
}